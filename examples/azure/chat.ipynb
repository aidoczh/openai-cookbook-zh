{"cells": [{"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["# Azure聊天完成示例\n", "\n", "本示例将介绍如何使用Azure OpenAI服务进行聊天完成，并包括有关内容过滤的信息。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "首先，我们安装必要的依赖项并导入我们将使用的库。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["! pip install \"openai>=1.0.0,<2.0.0\"\n", "! pip install python-dotenv\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import openai\n", "import dotenv\n", "\n", "dotenv.load_dotenv()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 认证\n", "\n", "Azure OpenAI 服务支持多种认证机制，包括 API 密钥和 Azure Active Directory 令牌凭据。\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["use_azure_active_directory = False  # 将此标志设置为 True，如果您正在使用 Azure Active Directory。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 使用API密钥进行身份验证\n", "\n", "要设置OpenAI SDK以使用*Azure API密钥*，我们需要将`api_key`设置为与您的端点关联的密钥（您可以在[Azure门户](https://portal.azure.com)的*\"资源管理\"*下的*\"密钥和端点\"*中找到此密钥）。您还将在此处找到您资源的端点。\n"]}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [], "source": ["if not use_azure_active_directory:\n", "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n", "    api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n", "\n", "    client = openai.AzureOpenAI(\n", "        azure_endpoint=endpoint,\n", "        api_key=api_key,\n", "        api_version=\"2023-09-01-preview\"\n", "    )\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 使用Azure Active Directory进行身份验证\n", "现在让我们看看如何通过Azure Active Directory进行身份验证。我们将从安装`azure-identity`库开始。这个库将提供我们需要进行身份验证的令牌凭据，并帮助我们通过`get_bearer_token_provider`辅助函数构建一个令牌凭据提供程序。建议使用`get_bearer_token_provider`而不是向`AzureOpenAI`提供静态令牌，因为这个API会自动为您缓存和刷新令牌。\n", "\n", "有关如何设置Azure Active Directory身份验证与Azure OpenAI的更多信息，请参阅[文档](https://learn.microsoft.com/azure/ai-services/openai/how-to/managed-identity)。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["! pip install \"azure-identity>=1.15.0\"\n"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n", "\n", "if use_azure_active_directory:\n", "    endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n", "\n", "    client = openai.AzureOpenAI(\n", "        azure_endpoint=endpoint,\n", "        azure_ad_token_provider=get_bearer_token_provider(DefaultAzureCredential(), \"https://cognitiveservices.azure.com/.default\"),\n", "        api_version=\"2023-09-01-preview\"\n", "    )\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 注意：如果未提供以下参数，则AzureOpenAI将从其对应的环境变量中推断出来：\n", "\n", "- `api_key` 从 `AZURE_OPENAI_API_KEY`\n", "- `azure_ad_token` 从 `AZURE_OPENAI_AD_TOKEN`\n", "- `api_version` 从 `OPENAI_API_VERSION`\n", "- `azure_endpoint` 从 `AZURE_OPENAI_ENDPOINT`\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 部署\n", "\n", "在本节中，我们将创建一个GPT模型的部署，以便用于生成聊天完成。\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 部署：在Azure OpenAI Studio中创建\n", "让我们部署一个模型以用于聊天完成。前往 https://portal.azure.com，找到您的Azure OpenAI资源，然后导航到Azure OpenAI Studio。点击“部署”选项卡，然后为您想要用于聊天完成的模型创建一个部署。您在模型中给出的部署名称将在下面的代码中使用。\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["deployment = \"\" # 在此处填写从门户获取的部署名称\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["## 创建聊天完成\n", "\n", "现在让我们使用我们构建的客户端来创建一个聊天完成。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 关于所有可能的参数，请参阅 <https://platform.openai.com/docs/api-reference/chat-completions/create>。\n", "response = client.chat.completions.create(\n", "    model=deployment,\n", "    messages=[\n", "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n", "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n", "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n", "        {\"role\": \"user\", \"content\": \"Orange.\"},\n", "    ],\n", "    temperature=0,\n", ")\n", "\n", "print(f\"{response.choices[0].message.role}: {response.choices[0].message.content}\")\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 创建一个流式聊天完成\n", "\n", "我们也可以流式传输响应。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["response = client.chat.completions.create(\n", "    model=deployment,\n", "    messages=[\n", "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n", "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n", "        {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n", "        {\"role\": \"user\", \"content\": \"Orange.\"},\n", "    ],\n", "    temperature=0,\n", "    stream=True\n", ")\n", "\n", "for chunk in response:\n", "    if len(chunk.choices) > 0:\n", "        delta = chunk.choices[0].delta\n", "\n", "        if delta.role:\n", "            print(delta.role + \": \", end=\"\", flush=True)\n", "        if delta.content:\n", "            print(delta.content, end=\"\", flush=True)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 内容过滤\n", "\n", "Azure OpenAI 服务包括对提示和完成响应进行内容过滤。您可以在[这里](https://learn.microsoft.com/azure/ai-services/openai/concepts/content-filter)了解有关内容过滤以及如何配置的更多信息。\n", "\n", "如果提示被内容过滤器标记，库将引发一个带有 `content_filter` 错误代码的 `BadRequestError` 异常。否则，您可以访问响应中的 `prompt_filter_results` 和 `content_filter_results`，查看内容过滤的结果以及哪些类别被标记。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 内容过滤器标记的提示\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import json\n", "\n", "messages = [\n", "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n", "    {\"role\": \"user\", \"content\": \"<text violating the content policy>\"}\n", "]\n", "\n", "try:\n", "    completion = client.chat.completions.create(\n", "        messages=messages,\n", "        model=deployment,\n", "    )\n", "except openai.BadRequestError as e:\n", "    err = json.loads(e.response.text)\n", "    if err[\"error\"][\"code\"] == \"content_filter\":\n", "        print(\"Content filter triggered!\")\n", "        content_filter_result = err[\"error\"][\"innererror\"][\"content_filter_result\"]\n", "        for category, details in content_filter_result.items():\n", "            print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 检查内容过滤器的结果\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["messages = [\n", "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n", "    {\"role\": \"user\", \"content\": \"What's the biggest city in Washington?\"}\n", "]\n", "\n", "completion = client.chat.completions.create(\n", "    messages=messages,\n", "    model=deployment,\n", ")\n", "print(f\"Answer: {completion.choices[0].message.content}\")\n", "\n", "# prompt content filter result in \"model_extra\" for azure\n", "prompt_filter_result = completion.model_extra[\"prompt_filter_results\"][0][\"content_filter_results\"]\n", "print(\"\\nPrompt content filter results:\")\n", "for category, details in prompt_filter_result.items():\n", "    print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")\n", "\n", "# completion content filter result\n", "print(\"\\nCompletion content filter results:\")\n", "completion_filter_result = completion.choices[0].model_extra[\"content_filter_results\"]\n", "for category, details in completion_filter_result.items():\n", "    print(f\"{category}:\\n filtered={details['filtered']}\\n severity={details['severity']}\")\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.0"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}