{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Azure音频耳语（预览）示例\n", "\n", "> 注意：openai库有更新版本可用。请参阅 https://github.com/openai/openai-python/discussions/742\n", "\n", "该示例展示了如何使用Azure OpenAI Whisper模型来转录音频文件。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 设置\n", "\n", "首先，我们安装必要的依赖项。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["! pip install \"openai>=0.28.1,<1.0.0\"\n", "! pip install python-dotenv\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["接下来，我们将导入我们的库并配置Python OpenAI SDK，以便与Azure OpenAI服务一起使用。\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> 注意：在这个示例中，我们通过在代码中设置变量来配置库以使用Azure API。对于开发环境，考虑设置环境变量而不是在代码中设置：\n", "\n", "```\n", "OPENAI_API_BASE\n", "OPENAI_API_KEY\n", "OPENAI_API_TYPE\n", "OPENAI_API_VERSION\n", "```\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [{"data": {"text/plain": ["True"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["import os\n", "import dotenv\n", "import openai\n", "\n", "\n", "dotenv.load_dotenv()\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["为了正确访问Azure OpenAI服务，我们需要在[Azure门户](https://portal.azure.com)上创建适当的资源（您可以在[Microsoft Docs](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal)中查看如何执行此操作的详细指南）\n", "\n", "资源创建完成后，我们首先需要使用的是其终结点。您可以在“资源管理”部分的“密钥和终结点”部分找到终结点。有了这个信息，我们将使用这些信息设置SDK：\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["openai.api_base = os.environ[\"OPENAI_API_BASE\"]\n", "\n", "# 支持Whisper的最低API版本\n", "openai.api_version = \"2023-09-01-preview\"\n", "\n", "# 请输入用于Whisper模型的部署ID。\n", "deployment_id = \"<deployment-id-for-your-whisper-model>\"\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["### 认证\n", "\n", "Azure OpenAI 服务支持多种认证机制，包括 API 密钥和 Azure 凭据。\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# 如果使用 Azure Active Directory 认证，请设置为 True。\n", "use_azure_active_directory = False\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["#### 使用API密钥进行身份验证\n", "\n", "要设置OpenAI SDK以使用*Azure API密钥*，我们需要将`api_type`设置为`azure`，并将`api_key`设置为与您的端点关联的密钥（您可以在[Azure门户](https://portal.azure.com)的*\"资源管理\"*下的*\"密钥和端点\"*中找到此密钥）。\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["if not use_azure_active_directory:\n", "    openai.api_type = 'azure'\n", "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["#### 使用Azure Active Directory进行身份验证\n", "现在让我们看看如何通过Microsoft Active Directory身份验证获取密钥。\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from azure.identity import DefaultAzureCredential\n", "\n", "if use_azure_active_directory:\n", "    default_credential = DefaultAzureCredential()\n", "    token = default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n", "\n", "    openai.api_type = 'azure_ad'\n", "    openai.api_key = token.token\n"]}, {"attachments": {}, "cell_type": "markdown", "metadata": {}, "source": ["令牌在一段时间内有效，之后将会过期。为了确保每个请求都携带一个有效的令牌，您可以通过连接到requests.auth来刷新即将过期的令牌：\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import typing\n", "import time\n", "import requests\n", "\n", "if typing.TYPE_CHECKING:\n", "    from azure.core.credentials import TokenCredential\n", "\n", "class TokenRefresh(requests.auth.AuthBase):\n", "\n", "    def __init__(self, credential: \"TokenCredential\", scopes: typing.List[str]) -> None:\n", "        self.credential = credential\n", "        self.scopes = scopes\n", "        self.cached_token: typing.Optional[str] = None\n", "\n", "    def __call__(self, req):\n", "        if not self.cached_token or self.cached_token.expires_on - time.time() < 300:\n", "            self.cached_token = self.credential.get_token(*self.scopes)\n", "        req.headers[\"Authorization\"] = f\"Bearer {self.cached_token.token}\"\n", "        return req\n", "\n", "if use_azure_active_directory:\n", "    session = requests.Session()\n", "    session.auth = TokenRefresh(default_credential, [\"https://cognitiveservices.azure.com/.default\"])\n", "\n", "    openai.requestssession = session\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 音频转录\n", "\n", "音频转录，或者说语音转文本，是将口语转换为文本的过程。使用`openai.Audio.transcribe`方法将音频文件流转录为文本。\n", "\n", "您可以从[GitHub上的Azure AI Speech SDK存储库](https://github.com/Azure-Samples/cognitive-services-speech-sdk/tree/master/sampledata/audiofiles)获取示例音频文件。\n"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["# 下载示例音频文件\n", "import requests\n", "\n", "sample_audio_url = \"https://github.com/Azure-Samples/cognitive-services-speech-sdk/raw/master/sampledata/audiofiles/wikipediaOcelot.wav\"\n", "audio_file = requests.get(sample_audio_url)\n", "with open(\"wikipediaOcelot.wav\", \"wb\") as f:\n", "    f.write(audio_file.content)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["transcription = openai.Audio.transcribe(\n", "    file=open(\"wikipediaOcelot.wav\", \"rb\"),\n", "    model=\"whisper-1\",\n", "    deployment_id=deployment_id,\n", ")\n", "print(transcription.text)\n"]}], "metadata": {"kernelspec": {"display_name": "venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.0"}, "orig_nbformat": 4}, "nbformat": 4, "nbformat_minor": 2}